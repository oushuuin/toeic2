<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8" />
  <title>è‡ªåŠ¨è¯†åˆ«ç­”é¢˜ç³»ç»Ÿ</title>
  <style>
    body {
      font-family: sans-serif;
      padding: 20px;
    }
    #video {
      width: 100%;
      max-width: 400px;
      border: 1px solid #ccc;
    }
    #gptAnswer {
      white-space: pre-wrap;
      border: 1px solid #ccc;
      padding: 10px;
      margin-top: 10px;
      background: #f9f9f9;
    }
    #startBtn {
      padding: 10px 20px;
      font-size: 16px;
    }
  </style>
</head>
<body>

  <h2>AI æ‹ç…§ç­”é¢˜ç³»ç»Ÿ</h2>
  <button id="startBtn">ğŸš€ å¯ç”¨è¯­éŸ³å’Œæ‘„åƒå¤´</button><br><br>

  <video id="video" autoplay playsinline></video>
  <canvas id="canvas" style="display:none;"></canvas>

  <h3>GPT å›ç­”ï¼š</h3>
  <div id="gptAnswer">è¯·ç‚¹å‡»æŒ‰é’®å¼€å§‹...</div>

  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>

  <script>
    const API_KEY = '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'; // æ›¿æ¢ä¸ºä½ çš„ OpenAI API Key
    const API_URL = 'https://api.openai.com/v1/chat/completions';

    const startBtn = document.getElementById('startBtn');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const gptAnswer = document.getElementById('gptAnswer');

    let voiceEnabled = false;
    let enVoice = null;
    let videoStream = null;
    let autoCaptureEnabled = false;
    let isCoolingDown = false;

    function initVoice() {
      const voices = speechSynthesis.getVoices();
      if (voices.length > 0) {
        enVoice = voices.find(v => v.lang === 'en-US') || voices[0];
        voiceEnabled = true;
      }
    }

    function speak(text) {
      if (!voiceEnabled || !text) return;
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'en-US';
      utter.voice = enVoice;
      speechSynthesis.speak(utter);
    }

    async function startCamera() {
      try {
        videoStream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment' },
          audio: false
        });
        video.srcObject = videoStream;
        autoCaptureEnabled = true;
        detectBrightnessLoop();
      } catch (err) {
        alert('æ‘„åƒå¤´æƒé™è·å–å¤±è´¥');
        console.error(err);
      }
    }

    function getFrameBrightness() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);
      let total = 0;
      for (let i = 0; i < frame.data.length; i += 4) {
        const r = frame.data[i];
        const g = frame.data[i + 1];
        const b = frame.data[i + 2];
        const brightness = (r + g + b) / 3;
        total += brightness;
      }
      const avg = total / (frame.data.length / 4);
      return avg;
    }

    let lastDark = true;

    function detectBrightnessLoop() {
      if (!autoCaptureEnabled) return;

      const brightness = getFrameBrightness();
      const isDark = brightness < 40;

      // å¦‚æœåŸæ¥æ˜¯æš—çš„ï¼Œç°åœ¨å˜äº®ï¼Œå¼€å§‹å»¶è¿Ÿ5ç§’æ‹ç…§
      if (lastDark && !isDark && !isCoolingDown) {
        console.log('æ£€æµ‹åˆ°äº®èµ·ï¼Œ5ç§’åæ‹ç…§');
        isCoolingDown = true;
        setTimeout(() => {
          if (!getFrameBrightness() < 40) {
            captureAndProcess();
          } else {
            console.log('äº®åº¦å˜åŒ–å–æ¶ˆæ‹ç…§ï¼ˆå˜æš—ï¼‰');
          }
          isCoolingDown = false;
        }, 5000);
      }

      lastDark = isDark;
      setTimeout(detectBrightnessLoop, 1000);
    }

    async function captureAndProcess() {
      gptAnswer.textContent = 'è¯†åˆ«ä¸­...';

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const blob = await new Promise(resolve =>
        canvas.toBlob(resolve, 'image/jpeg', 0.9)
      );

      try {
        const result = await Tesseract.recognize(blob, 'chi_sim+eng');
        const text = result.data.text.trim();

        const messages = [
          {
            role: 'system',
            content: 'åšå‡ºtoeicè‹±è¯­é¢˜çš„ç­”æ¡ˆï¼ŒæŒ‰é¡ºåºç»™å‡ºçš„æ­£ç¡®é€‰é¡¹ï¼ˆä»…å›ç­”aæˆ–bæˆ–cæˆ–då³å¯ï¼Œä¸è¦å›ç­”åé¢å…·ä½“çš„é€‰é¡¹å†…å®¹ï¼‰'
          },
          {
            role: 'user',
            content: text
          }
        ];

        const response = await fetch(API_URL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${API_KEY}`
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages
          })
        });

        const data = await response.json();
        const answer = data.choices?.[0]?.message?.content?.trim() || 'æ— å›ç­”';
        gptAnswer.textContent = answer;
        speak(answer);
      } catch (err) {
        console.error(err);
        gptAnswer.textContent = 'è¯†åˆ«å¤±è´¥';
      }
    }

    // æŒ‰é’®å¯åŠ¨è¯­éŸ³å’Œæ‘„åƒå¤´
    startBtn.addEventListener('click', () => {
      initVoice();
      speak('Voice enabled');
      startCamera();
      startBtn.disabled = true;
      startBtn.textContent = 'âœ… å·²å¯ç”¨';
    });

    // iOSè¯­éŸ³å¿…é¡»ç‚¹å‡»äº¤äº’æ‰èƒ½å¯ç”¨
    speechSynthesis.getVoices();
    if (speechSynthesis.onvoiceschanged !== undefined) {
      speechSynthesis.onvoiceschanged = initVoice;
    }
  </script>
</body>
</html>