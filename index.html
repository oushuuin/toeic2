<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8" />
  <title>è‡ªåŠ¨è¯†åˆ«ç­”é¢˜ç³»ç»Ÿ</title>
  <style>
    body {
      font-family: sans-serif;
      padding: 20px;
    }
    #video {
      width: 100%;
      max-width: 400px;
      border: 1px solid #ccc;
    }
    #gptAnswer {
      white-space: pre-wrap;
      border: 1px solid #ccc;
      padding: 10px;
      margin-top: 10px;
      background: #f9f9f9;
    }
    #startBtn {
      padding: 10px 20px;
      font-size: 16px;
    }
  </style>
</head>
<body>

  <h2>AI è‡ªåŠ¨æ‹ç…§ç­”é¢˜ç³»ç»Ÿ</h2>
  <button id="startBtn">ğŸš€ å¯ç”¨è¯­éŸ³å’Œæ‘„åƒå¤´</button><br><br>

  <video id="video" autoplay playsinline></video>
  <canvas id="canvas" style="display:none;"></canvas>

  <h3>GPT å›ç­”ï¼š</h3>
  <div id="gptAnswer">è¯·ç‚¹å‡»æŒ‰é’®å¼€å§‹...</div>

  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>

  <script>
    const API_KEY = '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'; // æ›¿æ¢ä¸ºä½ çš„ OpenAI API Key
    const API_URL = 'https://api.openai.com/v1/chat/completions';

    const startBtn = document.getElementById('startBtn');
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const gptAnswer = document.getElementById('gptAnswer');

    let videoStream = null;
    let enVoice = null;
    let voiceEnabled = false;

    function initVoice() {
      const voices = speechSynthesis.getVoices();
      if (voices.length > 0) {
        enVoice = voices.find(v => v.lang === 'en-US') || voices[0];
        voiceEnabled = true;
      }
    }

    function speak(text) {
      if (!voiceEnabled || !text) return;
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'en-US';
      utter.voice = enVoice;
      speechSynthesis.speak(utter);
    }

    // ç”Ÿæˆâ€œæ»´â€å£°éŸ³
    function beep() {
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const oscillator = audioCtx.createOscillator();
      oscillator.type = 'square';
      oscillator.frequency.setValueAtTime(1000, audioCtx.currentTime); // 1000Hz
      oscillator.connect(audioCtx.destination);
      oscillator.start();
      setTimeout(() => {
        oscillator.stop();
        audioCtx.close();
      }, 150); // æŒç»­150æ¯«ç§’
    }

    async function startCamera() {
      try {
        videoStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false });
        video.srcObject = videoStream;
        startAutoCaptureLoop();
      } catch (err) {
        alert('æ‘„åƒå¤´æƒé™è·å–å¤±è´¥');
        console.error(err);
      }
    }

async function captureAndProcess() {
  gptAnswer.textContent = 'è¯†åˆ«ä¸­...';

  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  const blob = await new Promise(resolve => canvas.toBlob(resolve, 'image/jpeg', 0.9));

  try {
    const result = await Tesseract.recognize(blob, 'chi_sim+eng');
    const text = result.data.text.trim();

    console.log('ã€OCRè¯†åˆ«ç»“æœã€‘:', text);  // æ‰“å°OCRè¯†åˆ«çš„æ–‡å­—

    const messages = [
      {
        role: 'system',
        content: 'åšå‡ºtoeicè‹±è¯­é¢˜çš„ç­”æ¡ˆï¼ŒæŒ‰é¡ºåºç»™å‡ºçš„æ­£ç¡®é€‰é¡¹ï¼ˆä»…å›ç­”aæˆ–bæˆ–cæˆ–då³å¯ï¼Œä¸è¦å›ç­”åé¢å…·ä½“çš„é€‰é¡¹å†…å®¹ï¼‰'
      },
      {
        role: 'user',
        content: text
      }
    ];

    const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages
      })
    });

    const data = await response.json();

    console.log('ã€OpenAIæ¥å£è¿”å›å®Œæ•´æ•°æ®ã€‘:', data);  // æ‰“å°æ¥å£è¿”å›çš„å®Œæ•´æ•°æ®

    const answer = data.choices?.[0]?.message?.content?.trim() || 'æ— å›ç­”';
    gptAnswer.textContent = answer;
    speak(answer);
  } catch (err) {
    console.error('è¯†åˆ«æˆ–è¯·æ±‚å‡ºé”™:', err);
    gptAnswer.textContent = 'è¯†åˆ«å¤±è´¥';
  }
}

        const response = await fetch(API_URL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${API_KEY}`
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages
          })
        });

        const data = await response.json();
        const answer = data.choices?.[0]?.message?.content?.trim() || 'æ— å›ç­”';
        gptAnswer.textContent = answer;
        speak(answer);
      } catch (err) {
        console.error(err);
        gptAnswer.textContent = 'è¯†åˆ«å¤±è´¥';
      }
    }

    // å¾ªç¯é€»è¾‘ï¼šå“å£°->3ç§’åæ‹ç…§è¯†åˆ«->å›ç­”->1åˆ†é’Ÿåå“å£°->3ç§’åæ‹ç…§è¯†åˆ«->å¾ªç¯
    async function startAutoCaptureLoop() {
      while(true) {
        beep(); // å“å£°
        await new Promise(r => setTimeout(r, 3000)); // ç­‰3ç§’
        await captureAndProcess();
        await new Promise(r => setTimeout(r, 60000)); // ç­‰1åˆ†é’Ÿ
        beep(); // ç¬¬äºŒæ¬¡å“å£°
        await new Promise(r => setTimeout(r, 3000)); // ç­‰3ç§’
        await captureAndProcess();
      }
    }

    // æŒ‰é’®å¯åŠ¨è¯­éŸ³å’Œæ‘„åƒå¤´
    startBtn.addEventListener('click', () => {
      initVoice();
      speak('Voice enabled');
      startCamera();
      startBtn.disabled = true;
      startBtn.textContent = 'âœ… å·²å¯ç”¨';
    });

    // é¢„åŠ è½½è¯­éŸ³åˆ—è¡¨ï¼Œç¡®ä¿iOSå…¼å®¹
    speechSynthesis.getVoices();
    if (speechSynthesis.onvoiceschanged !== undefined) {
      speechSynthesis.onvoiceschanged = initVoice;
    }
  </script>
</body>
</html>